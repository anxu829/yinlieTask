{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 首先对于大图，需要将其切成小图，放在tmp中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import shutil\n",
    "import os\n",
    "sys.path.append('/jinkevi')\n",
    "from common.el_process import  grid_cut \n",
    "from common.el_precut import ElPreCuter\n",
    "\n",
    "cuter = ElPreCuter\n",
    "testimg  = cv2.imread('../PA03181010804974.jpg')\n",
    "testimg  = cuter().get_precut(testimg,False)\n",
    "dataset  = grid_cut(testimg,6,12,True)\n",
    "\n",
    "if os.path.exists('../data/testimg/'):\n",
    "    shutil.rmtree('../data/testimg/')\n",
    "os.mkdir('../data/testimg/')\n",
    "for iidx  , i in enumerate(dataset[1][0]):\n",
    "    for  jidx ,j in enumerate( dataset[1][1] ):\n",
    "        if i != dataset[1][0][-1] and j != dataset[1][1][-1]:\n",
    "            img = dataset[0][(i,j)]\n",
    "            cv2.imwrite(\n",
    "                os.path.join('../data/testimg/' + str(iidx) + '_' + str(jidx) + '.jpg'),img\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从文件夹中取出小图进行测试 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Detectron ops lib: /usr/local/caffe2_build/lib/libcaffe2_detectron_ops_gpu.so\n",
      "WARNING cnn.py:  40: [====DEPRECATE WARNING====]: you are creating an object from CNNModelHelper class which will be deprecated soon. Please use ModelHelper object with brew module. For more information, please refer to caffe2.ai and python/brew.py, python/brew_test.py for more information.\n",
      "INFO net.py:  57: Loading weights from: /tmp/output/model_yinlie.pkl\n",
      "we now start to detect  ../data/testimg//*.jpg\n",
      "--------------------------------------------------------------------------------\n",
      "count: 0.0355401039124\n",
      "2\n",
      "../data/testimg/2_0.jpg\n",
      "l1 is  2.1190897751506874\n",
      "0.9883605\n",
      "compare with shanxian :  True\n",
      "diff of y is  161\n",
      "shanxian diff is  55.125\n",
      "if large yilie True\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "\n",
    "# Copyright (c) 2017-present, Facebook, Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "##############################################################################\n",
    "\n",
    "\"\"\"Perform inference on a single image or all images with a certain extension\n",
    "(e.g., .jpg) in a folder.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import cv2  # NOQA (Must import before importing caffe2 due to bug in cv2)\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle \n",
    "\n",
    "from caffe2.python import workspace\n",
    "\n",
    "from core.config import assert_and_infer_cfg\n",
    "from core.config import cfg\n",
    "from core.config import merge_cfg_from_file\n",
    "from utils.timer import Timer\n",
    "import core.test_engine as infer_engine\n",
    "import datasets.dummy_datasets as dummy_datasets\n",
    "import utils.c2 as c2_utils\n",
    "import utils.logging\n",
    "import utils.vis as vis_utils\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/jinkevi/el_server/')\n",
    "import  post_process.yinlie_utils.extract_yinlie_feature as fy\n",
    "\n",
    "from easydict import EasyDict as easy\n",
    "\n",
    "\n",
    "c2_utils.import_detectron_ops()\n",
    "# OpenCL may be enabled by default in OpenCV3; disable it because it's not\n",
    "# thread safe and causes unwanted GPU memory allocations.\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "import  matplotlib.pyplot  as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def testimg(args):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    merge_cfg_from_file(args.cfg)\n",
    "    cfg.TEST.WEIGHTS = args.weights\n",
    "    cfg.NUM_GPUS = 1\n",
    "    assert_and_infer_cfg()\n",
    "    model = infer_engine.initialize_model_from_cfg()\n",
    "    dummy_coco_dataset = dummy_datasets.get_coco_dataset('yinlie')\n",
    "\n",
    "    if os.path.isdir(args.im_or_folder):\n",
    "        im_list = glob.iglob(args.im_or_folder + '/*.' + args.image_ext)\n",
    "    else:\n",
    "        im_list = [args.im_or_folder]\n",
    "    print('we now start to detect '  , args.im_or_folder + '/*.' + args.image_ext)\n",
    "\n",
    "    \n",
    "    count  = 0 \n",
    "    for i, im_name in enumerate(im_list):\n",
    "\n",
    "        out_name = os.path.join(\n",
    "            args.output_dir, '{}'.format(os.path.basename(im_name) + '.pdf')\n",
    "        )\n",
    "\n",
    "        im = cv2.imread(im_name)\n",
    "        timers = defaultdict(Timer)\n",
    "        t = time.time()\n",
    "        with c2_utils.NamedCudaScope(0):\n",
    "            \n",
    "            start  = time.time()\n",
    "            cls_boxes, cls_segms, cls_keyps = infer_engine.im_detect_all(\n",
    "                model, im, None, timers=timers\n",
    "            )\n",
    "            end = time.time()\n",
    "            \n",
    "            a = cls_boxes[1][:,4][0]   if cls_boxes[1].shape[0] != 0 else 0\n",
    "            b = cls_boxes[2][:,4][0]   if cls_boxes[2].shape[0] != 0 else 0\n",
    "            \n",
    "            if a > 0.985:\n",
    "                count +=1 \n",
    "\n",
    "                xmin , ymin, xmax ,ymax = cls_boxes[1][0][:4].astype(int)\n",
    "                  \n",
    "                \n",
    "                jiaYinlieBx = [xmin , ymin, xmax ,ymax ]\n",
    "                subimg = cv2.cvtColor(im,cv2.COLOR_RGB2GRAY)\n",
    "                shanxians = fy.find_shanxian_row(subimg)[1]\n",
    "\n",
    "                \n",
    "                yinlieMask, shanxian, labels3 = fy.getYinlieInfo(subimg,jiaYinlieBx,verbose = False,padding = 10)\n",
    "                status , l1 , mask   = fy.getThicknessInfo(subimg, jiaYinlieBx ,shanxian, labels3, verbose= False , thick=3,thres = 10)\n",
    "                \n",
    "\n",
    "                # 然后获得焊点的外围\n",
    "                inner_xmin = 15\n",
    "                inner_xmax = subimg.shape[1] - 15\n",
    "                inner_ymin = shanxians[0] // 3\n",
    "                inner_ymax = shanxians[-1] + (subimg.shape[0] - shanxians[-1] ) *2 // 3\n",
    "\n",
    "                subimg  = cv2.rectangle(subimg, (xmin,ymin), (xmax,ymax), (0,255,0), 2)\n",
    "                subimg  = cv2.rectangle(subimg, (inner_xmin , inner_ymin) ,(inner_xmax,inner_ymax) ,(0,255,0) ,2)\n",
    "                \n",
    "                if status == False:\n",
    "                    count +=1 \n",
    "                    \n",
    "                    # 执行第二阶段\n",
    "                    print('-'*80)\n",
    "                    print('count:' , end - start)\n",
    "                    print(count)\n",
    "                    print(im_name)\n",
    "                    print('l1 is ', l1)\n",
    "                    print(cls_boxes[1][:,4][0])\n",
    "\n",
    "                    print('compare with shanxian : ',(ymax - ymin ) > np.diff(shanxians ).mean())\n",
    "                    print('diff of y is ' ,ymax - ymin)\n",
    "                    print('shanxian diff is ' ,0.7 * np.diff(shanxians ).mean())\n",
    "                    print('if large yilie',(ymax - ymin ) > 0.8 * np.diff(shanxians ).mean())\n",
    "\n",
    "\n",
    "                    plt.figure(figsize = (10,10))\n",
    "                    plt.title(status)\n",
    "                    plt.imshow(subimg,'gray')\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n",
    "    utils.logging.setup_logging(__name__)\n",
    "    args = easy()\n",
    "    args.cfg = '/jinkevi/el_server/detectron/configs/EL_configs/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN_yinlie.yaml'\n",
    "    args.weights = '/tmp/output/model_yinlie.pkl'\n",
    "    args.output_dir = '/tmp/output/testimg_output'\n",
    "    args.im_or_folder = '../data/testimg/' \n",
    "    args.image_ext = 'jpg'\n",
    "    testimg(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.69006752597979"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
